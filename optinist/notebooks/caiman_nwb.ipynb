{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e25ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from dateutil.tz import tzlocal\n",
    "\n",
    "# caiman\n",
    "import caiman as cm\n",
    "from caiman.paths import caiman_datadir\n",
    "from caiman.utils.utils import download_demo\n",
    "from caiman.source_extraction.cnmf import params as params\n",
    "from caiman.motion_correction import MotionCorrect\n",
    "from caiman.source_extraction.cnmf import cnmf as cnmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ebc489",
   "metadata": {},
   "outputs": [],
   "source": [
    "caiman_datadir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b82953",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = [join_file_path(\n",
    "    caiman_datadir(), \n",
    "    'example_movies',\n",
    "    'Sue_2x_3000_40_-46.nwb'\n",
    ")]\n",
    "# estimates save path can be same or different from raw data path\n",
    "\n",
    "save_path = join_file_path(\n",
    "    caiman_datadir(), \n",
    "    'example_movies',\n",
    "    'Sue_2x_3000_40_-46_CNMF_estimates.nwb'\n",
    ")\n",
    "# filename to be created or processed\n",
    "\n",
    "# dataset dependent parameters\n",
    "fr = 15.  # imaging rate in frames per second\n",
    "decay_time = 0.4  # length of a typical transient in seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dac7ab",
   "metadata": {},
   "source": [
    "### CaImAnの関数でNWB保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a691c20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NWBがない場合保存する\n",
    "if not os.path.exists(fnames[0]):\n",
    "    \n",
    "    # tifロードする\n",
    "    fnames_orig = 'Sue_2x_3000_40_-46.tif'\n",
    "    if fnames_orig in ['Sue_2x_3000_40_-46.tif', 'demoMovie.tif']:\n",
    "        fnames_orig = [download_demo(fnames_orig)]\n",
    "    orig_movie = cm.load(fnames_orig, fr=fr)\n",
    "\n",
    "    # save file in NWB format with various additional info\n",
    "    orig_movie.save(\n",
    "        fnames[0], \n",
    "        sess_desc='test', \n",
    "        identifier='demo 1',\n",
    "        imaging_plane_description='single plane',\n",
    "        emission_lambda=520.0, indicator='GCAMP6f',\n",
    "        location='parietal cortex',\n",
    "        experimenter='Sue Ann Koay', lab_name='Tank Lab',\n",
    "        institution='Princeton U',\n",
    "        experiment_description='Experiment Description',\n",
    "        session_id='Session 1',\n",
    "        var_name_hdf5='TwoPhotonSeries')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a163172",
   "metadata": {},
   "source": [
    "### Motion Correctのパラメータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568ab926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# motion_correction parameter\n",
    "dxy = (2., 2.)  # spatial resolution in x and y in (um per pixel)\n",
    "# note the lower than usual spatial resolution here\n",
    "max_shift_um = (12., 12.)  # maximum shift in um\n",
    "patch_motion_um = (100., 100.)  # patch size for non-rigid correction in um\n",
    "pw_rigid = True       # flag to select rigid vs pw_rigid motion correction\n",
    "# maximum allowed rigid shift in pixels\n",
    "max_shifts = [int(a/b) for a, b in zip(max_shift_um, dxy)]\n",
    "# start a new patch for pw-rigid motion correction every x pixels\n",
    "strides = tuple([int(a/b) for a, b in zip(patch_motion_um, dxy)])\n",
    "# overlap between patches (size of patch in pixels: strides+overlaps)\n",
    "overlaps = (24, 24)\n",
    "# maximum deviation allowed for patch with respect to rigid shifts\n",
    "max_deviation_rigid = 3\n",
    "\n",
    "mc_dict = {\n",
    "    'fnames': fnames,\n",
    "    'fr': fr,\n",
    "    'decay_time': decay_time,\n",
    "    'dxy': dxy,\n",
    "    'pw_rigid': pw_rigid,\n",
    "    'max_shifts': max_shifts,\n",
    "    'strides': strides,\n",
    "    'overlaps': overlaps,\n",
    "    'max_deviation_rigid': max_deviation_rigid,\n",
    "    'border_nan': 'copy',\n",
    "    #'var_name_hdf5': 'acquisition/TwoPhotonSeries'\n",
    "    'var_name_hdf5': 'TwoPhotonSeries'\n",
    "}\n",
    "\n",
    "opts = params.CNMFParams(params_dict=mc_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043977b0",
   "metadata": {},
   "source": [
    "### motion correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cfacfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7629792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = opts.get_group('motion')\n",
    "# param['pw_rigid'] = False\n",
    "\n",
    "mc = MotionCorrect(\n",
    "    fnames, \n",
    "    dview=dview, \n",
    "    var_name_hdf5=opts.data['var_name_hdf5'], \n",
    "    **param\n",
    ")\n",
    "mc.motion_correct(save_movie=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2d800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% MEMORY MAPPING\n",
    "border_to_0 = 0 if mc.border_nan == 'copy' else mc.border_to_0\n",
    "# you can include the boundaries of the FOV if you used the 'copy' option\n",
    "# during motion correction, although be careful about the components near\n",
    "# the boundaries\n",
    "\n",
    "# memory map the file in order 'C'\n",
    "fname_new = cm.save_memmap(\n",
    "    mc.mmap_file, base_name='memmap_', order='C',\n",
    "    border_to_0=border_to_0)  # exclude borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae52e842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now load the file\n",
    "Yr, dims, T = cm.load_memmap(fname_new)   # (3000, 28900)\n",
    "mc_images = np.reshape(Yr.T, [T] + list(dims), order='F')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f2cf0e",
   "metadata": {},
   "source": [
    "### CNMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2ee3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter\n",
    "p = 1                    # order of the autoregressive system\n",
    "gnb = 2                  # number of global background components\n",
    "merge_thr = 0.85         # merging threshold, max correlation allowed\n",
    "rf = 15\n",
    "# half-size of the patches in pixels. e.g., if rf=25, patches are 50x50\n",
    "stride_cnmf = 6          # amount of overlap between the patches in pixels\n",
    "K = 4                    # number of components per patch\n",
    "gSig = [4, 4]            # expected half size of neurons in pixels\n",
    "# initialization method (if analyzing dendritic data using 'sparse_nmf')\n",
    "method_init = 'greedy_roi'\n",
    "ssub = 2                     # spatial subsampling during initialization\n",
    "tsub = 2                     # temporal subsampling during intialization\n",
    "\n",
    "# parameters for component evaluation\n",
    "opts_dict = {\n",
    "    'fnames': fnames,\n",
    "     'fr': fr,\n",
    "     'nb': gnb,\n",
    "     'rf': rf,\n",
    "     'K': K,\n",
    "     'gSig': gSig,\n",
    "     'stride': stride_cnmf,\n",
    "     'method_init': method_init,\n",
    "     'rolling_sum': True,\n",
    "     'merge_thr': merge_thr,\n",
    "     'n_processes': n_processes,\n",
    "     'only_init': True,\n",
    "     'ssub': ssub,\n",
    "     'tsub': tsub\n",
    "}\n",
    "\n",
    "opts.change_params(params_dict=opts_dict);\n",
    "# %% RUN CNMF ON PATCHES\n",
    "# First extract spatial and temporal components on patches and combine them\n",
    "# for this step deconvolution is turned off (p=0)\n",
    "opts.change_params({'p': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f149207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fp = np.memmap('a.mmap', dtype='float32', mode='w+', shape=images.shape, order='C')\n",
    "# fp[:] = images[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f31417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.mmapping.load_memmap(fname_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1830d7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm = cnmf.CNMF(n_processes, params=opts, dview=dview)\n",
    "cnm = cnm.fit(mc_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e990212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% plot contours of found components\n",
    "Cn = cm.local_correlations(mc_images, swap_dim=False)\n",
    "Cn[np.isnan(Cn)] = 0\n",
    "cnm.estimates.plot_contours(img=Cn)\n",
    "plt.title('Contour plots of found components')\n",
    "\n",
    "#%% save results in a separate file (just for demonstration purposes)\n",
    "cnm.estimates.Cn = Cn\n",
    "# cnm.save(fname_new[:-4]+'hdf5')\n",
    "#cm.movie(Cn).save(fname_new[:-5]+'_Cn.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3ccecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cnm.estimates.C.shape)\n",
    "print(cnm.estimates.f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21e50bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm.estimates.detrend_df_f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b21866",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm.estimates.F_dff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e013c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm.estimates.evaluate_components(fp, cnm.params, dview=dview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dbc6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm.estimates.save_NWB(\n",
    "    save_path, \n",
    "    imaging_rate=fr, \n",
    "    session_start_time=datetime.now(tzlocal()), \n",
    "    raw_data_file=fnames[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13a6f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "fr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52511e68",
   "metadata": {},
   "source": [
    "### NWB保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8374108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynwb import NWBFile, TimeSeries, NWBHDF5IO\n",
    "from pynwb.base import Images\n",
    "from pynwb.image import GrayscaleImage\n",
    "from pynwb.device import Device\n",
    "from pynwb.ophys import (\n",
    "    OpticalChannel, ImageSeries, ImageSegmentation,\n",
    "    Fluorescence, MotionCorrection, CorrectedImageStack\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67ad12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NWBFile作成\n",
    "identifier = 'CaImAn'\n",
    "session_start_time=datetime.now(tzlocal())\n",
    "exp_desc=None\n",
    "\n",
    "nwbfile = NWBFile(\n",
    "    'CaImAn Results', \n",
    "    identifier, \n",
    "    session_start_time, \n",
    "    experiment_description=exp_desc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245a7488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deviceを追加\n",
    "device = Device('imaging_device')\n",
    "nwbfile.add_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac77ff92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aquisitionを追加\n",
    "emission_lambda=520.0\n",
    "excitation_lambda=488.0\n",
    "imaging_rate=30.\n",
    "indicator='OGB-1'\n",
    "location='brain'\n",
    "\n",
    "optical_channel = OpticalChannel(\n",
    "    'OpticalChannel',\n",
    "    'main optical channel',\n",
    "    emission_lambda=emission_lambda\n",
    ")\n",
    "\n",
    "nwbfile.create_imaging_plane(\n",
    "    name='ImagingPlane',\n",
    "    optical_channel=optical_channel,\n",
    "    description='some imaging plane description',\n",
    "    device=device,\n",
    "    excitation_lambda=excitation_lambda,\n",
    "    imaging_rate=imaging_rate,\n",
    "    indicator=indicator,\n",
    "    location=location\n",
    ")\n",
    "\n",
    "nwbfile.add_acquisition(\n",
    "    ImageSeries(\n",
    "        name='TwoPhotonSeries',\n",
    "        external_file=[fnames[0]],\n",
    "        format='external',\n",
    "        rate=imaging_rate,\n",
    "        starting_frame=[0]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77c22d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.processing.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c9ca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.imaging_planes['ImagingPlane'].imaging_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d4b07a",
   "metadata": {},
   "source": [
    "### ophys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779eb41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.create_processing_module(\n",
    "    'ophys', 'contains caiman estimates for the main imaging plane')\n",
    "# ophys_module = nwbfile.create_processing_module(\n",
    "#     'ophys', 'contains caiman estimates for the main imaging plane')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29bfbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.processing['ophys']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60afbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "border_to_0 = 0 if mc.border_nan == 'copy' else mc.border_to_0\n",
    "\n",
    "# # memory mapping\n",
    "# fname_new = save_memmap(\n",
    "#     mc.mmap_file,\n",
    "#     base_name='memmap_',\n",
    "#     order='C',\n",
    "#     border_to_0=border_to_0\n",
    "# )\n",
    "\n",
    "# # now load the file\n",
    "# Yr, dims, T = load_memmap(fname_new)\n",
    "# images = np.array(np.reshape(\n",
    "#     Yr.T, [T] + list(dims), order='F'))\n",
    "# mc_images = Yr.T.reshape((T,) + dims, order='F')\n",
    "# mc_images = np.array(mc_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cfd399",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames_orig = 'Sue_2x_3000_40_-46.tif'\n",
    "if fnames_orig in ['Sue_2x_3000_40_-46.tif']:\n",
    "    fnames_orig = [download_demo(fnames_orig)]\n",
    "orig_movie = cm.load(fnames_orig, fr=fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3319ef7e",
   "metadata": {},
   "source": [
    "### motion correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd650b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# motion correction\n",
    "original = ImageSeries(\n",
    "    name='original',  # this must be named \"corrected\"\n",
    "    data=orig_movie,\n",
    "    unit='na',\n",
    "    format='raw',\n",
    "    starting_time=0.0,\n",
    "    rate=1.0\n",
    ")\n",
    "\n",
    "corrected = ImageSeries(\n",
    "    name='corrected',  # this must be named \"corrected\"\n",
    "    data=mc_images,\n",
    "    unit='na',\n",
    "    format='raw',\n",
    "    starting_time=0.0,\n",
    "    rate=1.0\n",
    ")\n",
    "\n",
    "xy_translation_data =  (np.array(mc.x_shifts_els), np.array(mc.y_shifts_els)) if param['pw_rigid'] else np.array(mc.shifts_rig)\n",
    "xy_translation = TimeSeries(\n",
    "    name='xy_translation',\n",
    "    data=xy_translation_data,\n",
    "    unit='pixels',\n",
    "    starting_time=0.0,\n",
    "    rate=1.0,\n",
    ")\n",
    "\n",
    "corrected_image_stack = CorrectedImageStack(\n",
    "    corrected=corrected,\n",
    "    original=original,\n",
    "    xy_translation=xy_translation,\n",
    ")\n",
    "\n",
    "motion_correction = MotionCorrection(\n",
    "    corrected_image_stacks=corrected_image_stack\n",
    ")\n",
    "nwbfile.processing['ophys'].add(motion_correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1b40d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.processing['ophys'].add(ImageSegmentation())\n",
    "# nwbfile.processing['ophys'].add_data_interface(fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219413b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with NWBHDF5IO('aa.nwb', 'w') as io:\n",
    "#     io.write(nwbfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e129add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plane_segmentation = nwbfile.processing['ophys'].data_interfaces[\n",
    "#     'ImageSegmentation'].create_plane_segmentation(\n",
    "#     name='PlaneSegmentation',\n",
    "#     description='CNMF_ROIs',\n",
    "#     imaging_plane=list(nwbfile.imaging_planes.values())[0],\n",
    "#     reference_images=list(nwbfile.acquisition.values())[0]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c443de",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.processing['ophys'].data_interfaces['ImageSegmentation'].create_plane_segmentation(\n",
    "    name='PlaneSegmentation',\n",
    "    description='CNMF_ROIs',\n",
    "    imaging_plane=list(nwbfile.imaging_planes.values())[0],\n",
    "    reference_images=list(nwbfile.acquisition.values())[0]\n",
    ")\n",
    "plane_segmentation = nwbfile.processing['ophys'].data_interfaces[\n",
    "        'ImageSegmentation'].plane_segmentations['PlaneSegmentation']\n",
    "\n",
    "# plane_segmentation.add_column('r', 'description of r values')\n",
    "# plane_segmentation.add_column('snr', 'signal to noise ratio')\n",
    "\n",
    "plane_segmentation.add_column('accepted', 'in accepted list')\n",
    "plane_segmentation.add_column('rejected', 'in rejected list')\n",
    "\n",
    "if cnm.estimates.cnn_preds is not None:\n",
    "    plane_segmentation.add_column('cnn', 'description of CNN')\n",
    "if cnm.estimates.idx_components is not None:\n",
    "    plane_segmentation.add_column('keep', 'in idx_components')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9e69f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'accepted' in plane_segmentation.colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe99847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plane_segmentation = nwbfile.processing['ophys'].data_interfaces[\n",
    "#         'ImageSegmentation'].create_plane_segmentation(\n",
    "#     name='PlaneSegmentation',\n",
    "#     description='CNMF_ROIs',\n",
    "#     imaging_plane=list(nwbfile.imaging_planes.values())[0],\n",
    "#     reference_images=list(nwbfile.acquisition.values())[0]\n",
    "# )\n",
    "\n",
    "# # plane_segmentation.add_column('r', 'description of r values')\n",
    "# # plane_segmentation.add_column('snr', 'signal to noise ratio')\n",
    "\n",
    "# plane_segmentation.add_column('accepted', 'in accepted list')\n",
    "# plane_segmentation.add_column('rejected', 'in rejected list')\n",
    "\n",
    "# if cnm.estimates.cnn_preds is not None:\n",
    "#     plane_segmentation.add_column('cnn', 'description of CNN')\n",
    "# if cnm.estimates.idx_components is not None:\n",
    "#     plane_segmentation.add_column('keep', 'in idx_components')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edae93f1",
   "metadata": {},
   "source": [
    "### ROIのカラムを追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e487b7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cells = cnm.estimates.A.shape[-1]\n",
    "for i in range(n_cells):\n",
    "    add_roi_kwargs = dict(\n",
    "        image_mask=cnm.estimates.A.T[i].T.toarray().reshape(cnm.estimates.dims),\n",
    "#         r=cnm.estimates.r_values[i],\n",
    "#         snr=cnm.estimates.SNR_comp[i],\n",
    "        accepted=False,\n",
    "        rejected=False\n",
    "    )\n",
    "\n",
    "    if hasattr(cnm.estimates, 'accepted_list'):\n",
    "        add_roi_kwargs.update(accepted=i in cnm.estimates.accepted_list)\n",
    "    if hasattr(cnm.estimates, 'rejected_list'):\n",
    "        add_roi_kwargs.update(rejected=i in cnm.estimates.rejected_list)\n",
    "    if cnm.estimates.cnn_preds is not None:\n",
    "        add_roi_kwargs.update(cnn=cnm.estimates.cnn_preds[i])\n",
    "    if cnm.estimates.idx_components is not None:\n",
    "        add_roi_kwargs.update(keep=i in cnm.estimates.idx_components)\n",
    "\n",
    "    plane_segmentation.add_roi(**add_roi_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f265eca",
   "metadata": {},
   "source": [
    "### backgroundsのカラムを追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19896906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backgrounds\n",
    "for bg in cnm.estimates.b.T:\n",
    "    add_bg_roi_kwargs = dict(\n",
    "        image_mask=bg.reshape(cnm.estimates.dims),\n",
    "#         r=np.nan,\n",
    "#         snr=np.nan,\n",
    "        accepted=False,\n",
    "        rejected=False\n",
    "    )\n",
    "    if 'keep' in plane_segmentation.colnames:\n",
    "        add_bg_roi_kwargs.update(keep=False)\n",
    "    if 'cnn' in plane_segmentation.colnames:\n",
    "        add_bg_roi_kwargs.update(cnn=np.nan)\n",
    "    plane_segmentation.add_roi(**add_bg_roi_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc75d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_roi_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7643de3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import caiman.utils.visualization as visualization\n",
    "cont = visualization.get_contours(\n",
    "    cnm.estimates.A, cnm.dims, thr=0.9, thr_method='nrg', swap_dim=False)\n",
    "cont_cent = np.zeros([len(cont), 2])\n",
    "for i in range(len(cont)):\n",
    "    cont_cent[i, :] = np.nanmean(cont[i]['coordinates'], axis=0)\n",
    "iscell = np.zeros(cont_cent.shape[0])\n",
    "iscell[cnm.estimates.idx_components] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533f7261",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_bg_roi_kwargs[\"image_mask\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7102eaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "iscell.reshape(1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9a3e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_segmentation.add_roi(\"iscell\", \"\", iscell.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f6d8f3",
   "metadata": {},
   "source": [
    "### Fluorescenceを登録"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0a54fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluo = Fluorescence()\n",
    "nwbfile.processing['ophys'].add(fluo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51820d39",
   "metadata": {},
   "source": [
    "### FluorescenceにROItableを追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342baff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_time = 0\n",
    "timestamps = np.arange(cnm.estimates.f.shape[1]) / imaging_rate + starting_time\n",
    "n_rois = cnm.estimates.A.shape[-1]\n",
    "n_bg = len(cnm.estimates.f)\n",
    "\n",
    "# Neurons\n",
    "\n",
    "# ROI\n",
    "#### ROI tableを作成\n",
    "data_interfaces = nwbfile.processing['ophys'].data_interfaces\n",
    "plane_seg = data_interfaces['ImageSegmentation'].plane_segmentations['PlaneSegmentation']\n",
    "fluo = data_interfaces['Fluorescence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d447b8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add roi\n",
    "table_name = 'ROIs'\n",
    "region = list(range(n_rois))\n",
    "name = 'RoiResponseSeries'\n",
    "data = cnm.estimates.C.T\n",
    "unit = 'lumens'\n",
    "\n",
    "region_roi = plane_seg.create_roi_table_region(\n",
    "    table_name, region=region)\n",
    "\n",
    "fluo.create_roi_response_series(\n",
    "    name=name,\n",
    "    data=data,\n",
    "    rois=region_roi,\n",
    "    unit=unit,\n",
    "    timestamps=timestamps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3265fca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Background\n",
    "\n",
    "table_name = 'Background'\n",
    "region = list(range(n_rois, n_rois+n_bg))\n",
    "name = 'Background_Fluorescence_Response'\n",
    "data = cnm.estimates.f.T\n",
    "unit = 'lumens'\n",
    "\n",
    "rt_region_bg = plane_seg.create_roi_table_region(\n",
    "    table_name, region=region)\n",
    "\n",
    "fluo.create_roi_response_series(\n",
    "    name=name,\n",
    "    data=data,\n",
    "    rois=rt_region_bg,\n",
    "    unit='lumens',\n",
    "    timestamps=timestamps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a9a510",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.processing['ophys'].add(TimeSeries(\n",
    "    name='residuals',\n",
    "    description='residuals',\n",
    "    data=cnm.estimates.YrA.T,\n",
    "    timestamps=timestamps, unit='NA'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6a4b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if hasattr(cnm.estimates, 'Cn'):\n",
    "#     images = Images('summary_images')\n",
    "#     images.add_image(GrayscaleImage(name='local_correlations', data=cnm.estimates.Cn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0d352a",
   "metadata": {},
   "source": [
    "### NWB保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63019ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with NWBHDF5IO(save_path, 'w') as io:\n",
    "    io.write(nwbfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6da9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with NWBHDF5IO(save_path, 'r') as io:\n",
    "    nwbfile = io.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9cd364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "def PrintOnlyDataset(name, obj):\n",
    "    if isinstance(obj, h5py.Dataset):\n",
    "        print(name)\n",
    "\n",
    "with h5py.File(save_path, \"r\") as f:\n",
    "    f.visititems(PrintOnlyDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5ea6e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76afed08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e64be26",
   "metadata": {},
   "source": [
    "### cnm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c82d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm2.estimates.plot_contours(img=Cn, idx=cnm.estimates.idx_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63ed380",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm.params.change_params({'p': p})\n",
    "cnm2 = cnm.refit(images, dview=dview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c89ee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% COMPONENT EVALUATION\n",
    "# the components are evaluated in three ways:\n",
    "#   a) the shape of each component must be correlated with the data\n",
    "#   b) a minimum peak SNR is required over the length of a transient\n",
    "#   c) each shape passes a CNN based classifier\n",
    "\n",
    "min_SNR = 2  # signal to noise ratio for accepting a component\n",
    "rval_thr = 0.85  # space correlation threshold for accepting a component\n",
    "cnn_thr = 0.99  # threshold for CNN based classifier\n",
    "cnn_lowest = 0.1 # neurons with cnn probability lower than this value are rejected\n",
    "\n",
    "cnm2.params.set(\n",
    "    'quality', {\n",
    "        'decay_time': decay_time, \n",
    "        'min_SNR': min_SNR,\n",
    "        'rval_thr': rval_thr,\n",
    "        'use_cnn': True,\n",
    "        'min_cnn_thr': cnn_thr,\n",
    "        'cnn_lowest': cnn_lowest\n",
    "    }\n",
    ");\n",
    "cnm2.estimates.evaluate_components(images, cnm2.params, dview=dview)\n",
    "#%%\n",
    "cnm2.estimates.Cn = Cn\n",
    "# cnm2.save(fname_new[:-4] + 'hdf5')\n",
    "# %% PLOT COMPONENTS\n",
    "cnm2.estimates.plot_contours(img=Cn, idx=cnm2.estimates.idx_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c48b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Extract DF/F values\n",
    "cnm2.estimates.detrend_df_f(quantileMin=8, frames_window=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db24e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Show final traces\n",
    "cnm2.estimates.view_components(img=Cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89894246",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm2.estimates.save_NWB(\n",
    "    save_path, \n",
    "    imaging_rate=fr, \n",
    "    session_start_time=datetime.now(tzlocal()), \n",
    "    raw_data_file=fnames[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5667e05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
