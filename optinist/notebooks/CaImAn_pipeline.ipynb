{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e5c8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as  pl\n",
    "import caiman as cm\n",
    "from caiman.utils.utils import download_demo\n",
    "from caiman.source_extraction.cnmf import params as params\n",
    "from caiman.utils.visualization import get_contours\n",
    "from scipy.sparse.linalg import inv\n",
    "from scipy.sparse import csc_matrix\n",
    "from caiman.base.rois import com\n",
    "from skimage.measure import find_contours\n",
    "import cv2\n",
    "from scipy.ndimage import binary_fill_holes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f12b514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import caiman as cm\n",
    "#%% start a cluster for parallel processing (if a cluster already exists it will be closed and a new session will be opened)\n",
    "if 'dview' in locals():\n",
    "    cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce45fbd7",
   "metadata": {},
   "source": [
    "### video load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabf01ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath = os.path.join('../data', 'Sue_2x_3000_40_-46.tif')\n",
    "# assert os.path.exists(filepath)\n",
    "filepath = 'Sue_2x_3000_40_-46.tif'\n",
    "fnames = [download_demo(filepath)]\n",
    "fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113ac03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_movie = False\n",
    "if display_movie:\n",
    "    m_orig = cm.load_movie_chain(fnames)\n",
    "    ds_ratio = 0.2\n",
    "    m_orig.resize(1, 1, ds_ratio).play(\n",
    "        q_max=99.5, fr=30, magnification=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a37eed",
   "metadata": {},
   "source": [
    "### setup parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7177f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset dependent parameters\n",
    "fr = 30                             # imaging rate in frames per second\n",
    "decay_time = 0.4                    # length of a typical transient in seconds\n",
    "\n",
    "# motion correction parameters\n",
    "strides = (48, 48)          # start a new patch for pw-rigid motion correction every x pixels\n",
    "overlaps = (24, 24)         # overlap between pathes (size of patch strides+overlaps)\n",
    "max_shifts = (6,6)          # maximum allowed rigid shifts (in pixels)\n",
    "max_deviation_rigid = 3     # maximum shifts deviation allowed for patch with respect to rigid shifts\n",
    "pw_rigid = True             # flag for performing non-rigid motion correction\n",
    "\n",
    "# parameters for source extraction and deconvolution\n",
    "p = 1                       # order of the autoregressive system\n",
    "gnb = 2                     # number of global background components\n",
    "merge_thr = 0.85            # merging threshold, max correlation allowed\n",
    "rf = 15                     # half-size of the patches in pixels. e.g., if rf=25, patches are 50x50\n",
    "stride_cnmf = 6             # amount of overlap between the patches in pixels\n",
    "K = 4                       # number of components per patch\n",
    "gSig = [4, 4]               # expected half size of neurons in pixels\n",
    "method_init = 'greedy_roi'  # initialization method (if analyzing dendritic data using 'sparse_nmf')\n",
    "ssub = 1                    # spatial subsampling during initialization\n",
    "tsub = 1                    # temporal subsampling during intialization\n",
    "\n",
    "# parameters for component evaluation\n",
    "min_SNR = 2.0               # signal to noise ratio for accepting a component\n",
    "rval_thr = 0.85              # space correlation threshold for accepting a component\n",
    "cnn_thr = 0.99              # threshold for CNN based classifier\n",
    "cnn_lowest = 0.1 # neurons with cnn probability lower than this value are rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7d8a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts_dict = {'fnames': fnames,\n",
    "            'fr': fr,\n",
    "            'decay_time': decay_time,\n",
    "            'strides': strides,\n",
    "            'overlaps': overlaps,\n",
    "            'max_shifts': max_shifts,\n",
    "            'max_deviation_rigid': max_deviation_rigid,\n",
    "            'pw_rigid': pw_rigid,\n",
    "            'p': p,\n",
    "            'nb': gnb,\n",
    "            'rf': rf,\n",
    "            'K': K, \n",
    "            'stride': stride_cnmf,\n",
    "            'method_init': method_init,\n",
    "            'rolling_sum': True,\n",
    "            'only_init': True,\n",
    "            'ssub': ssub,\n",
    "            'tsub': tsub,\n",
    "            'merge_thr': merge_thr, \n",
    "            'min_SNR': min_SNR,\n",
    "            'rval_thr': rval_thr,\n",
    "            'use_cnn': True,\n",
    "            'min_cnn_thr': cnn_thr,\n",
    "            'cnn_lowest': cnn_lowest}\n",
    "border_nan = 'copy' \n",
    "\n",
    "from caiman.source_extraction.cnmf import params as params\n",
    "opts = params.CNMFParams(params_dict=opts_dict)\n",
    "opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d806f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "'dview' in locals()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348a65f5",
   "metadata": {},
   "source": [
    "### setup cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989de3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% start a cluster for parallel processing (if a cluster already exists it will be closed and a new session will be opened)\n",
    "if 'dview' in locals():\n",
    "    cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506e26b7",
   "metadata": {},
   "source": [
    "### motion correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5cbdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from caiman.motion_correction import MotionCorrect\n",
    "# first we create a motion correction object with the parameters specified\n",
    "mc = MotionCorrect(fnames, dview=dview, **opts.get_group('motion'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0836ec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91a755e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#%% Run piecewise-rigid motion correction using NoRMCorre\n",
    "mc.motion_correct(save_movie=True)\n",
    "m_els = cm.load(mc.fname_tot_els)\n",
    "border_to_0 = 0 if mc.border_nan is 'copy' else mc.border_to_0 \n",
    "    # maximum shift to be used for trimming against NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c15fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% compare with original movie\n",
    "display_movie = False\n",
    "if display_movie:\n",
    "    m_orig = cm.load_movie_chain(fnames)\n",
    "    ds_ratio = 0.2\n",
    "    cm.concatenate([\n",
    "        m_orig.resize(1, 1, ds_ratio) - mc.min_mov*mc.nonneg_movie, \n",
    "        m_els.resize(1, 1, ds_ratio)\n",
    "    ], axis=2\n",
    "    ).play(fr=60, gain=15, magnification=2, offset=0)  # press q to exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd57d3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "fname_mc = mc.fname_tot_els if pw_rigid else mc.fname_tot_rig\n",
    "\n",
    "bord_px = 0 if border_nan is 'copy' else bord_px\n",
    "fname_new = cm.save_memmap(fname_mc, base_name='memmap_', order='C', border_to_0=bord_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dd9a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load memory mappable file\n",
    "Yr, dims, T = cm.load_memmap(fname_new)\n",
    "images = Yr.T.reshape((T,) + dims, order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90794dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from caiman.paths import memmap_frames_filename\n",
    "from caiman.mmapping import prepare_shape\n",
    "# np.arrayをmmapへ変換\n",
    "order = 'C'\n",
    "dims = images.shape[1:]\n",
    "T = images.shape[0]\n",
    "shape_mov = (np.prod(dims), T)\n",
    "\n",
    "file_path = \".\"\n",
    "dir_path = os.path.dirname(file_path)\n",
    "basename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "fname_tot = memmap_frames_filename(basename, dims, T, order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2967af1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmap_images = np.memmap(\n",
    "    os.path.join(dir_path, fname_tot),\n",
    "    mode='w+',\n",
    "    dtype=np.float32,\n",
    "    shape=prepare_shape(shape_mov),\n",
    "    order=order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64f0330",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmap_images = np.reshape(mmap_images.T, [T] + list(dims), order='F')\n",
    "mmap_images[:] = images[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2c7464",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_processes)\n",
    "print(dview)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da37e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from caiman.source_extraction import cnmf\n",
    "Ain = None\n",
    "\n",
    "cnm = cnmf.CNMF(n_processes=n_processes, dview=dview, Ain=Ain, params=opts)\n",
    "cnm.fit(mmap_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5620bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% plot contours of found components\n",
    "import caiman as cm\n",
    "Cn = cm.local_correlations(images.transpose(1,2,0))\n",
    "Cn[np.isnan(Cn)] = 0\n",
    "cnm.estimates.plot_contours_nb(img=Cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e59fced",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm.estimates.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ec8a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = get_contours(cnm.estimates.A, np.shape(Cn), swap_dim=swap_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea8c1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(coordinates))\n",
    "print(len(coordinates[0]['coordinates']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e520ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pl.imshow(Cn)\n",
    "for c in coordinates:\n",
    "    pl.plot(*c['coordinates'].T)\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e25bcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = 0.9\n",
    "thr_method = 'nrg'\n",
    "swap_dim = True\n",
    "cont = get_contours(\n",
    "    cnm.estimates.A, cnm.dims, thr=thr, thr_method=thr_method, swap_dim=True)\n",
    "cont_cent = np.zeros([len(cont), 2])\n",
    "sparse_rois = []\n",
    "for i in range(len(cont)):\n",
    "    cont_cent[i, :] = np.nanmean(cont[i]['coordinates'], axis=0)\n",
    "    sparse_rois.append(cont[i]['coordinates'].T)\n",
    "\n",
    "iscell = np.zeros(cont_cent.shape[0]).astype(np.bool)\n",
    "iscell[cnm.estimates.idx_components] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664e74c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "for c in sparse_rois:\n",
    "    plt.plot(*c)\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9853e2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(im[~np.isnan(im)].shape)\n",
    "# print(im[np.isnan(im)].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29b0495",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "A = cnm.estimates.A\n",
    "d, nr = np.shape(A)\n",
    "# cm = com(A, *dims)\n",
    "\n",
    "# for each patches\n",
    "ims = []\n",
    "for i in range(nr):\n",
    "    pars = dict()\n",
    "    # we compute the cumulative sum of the energy of the Ath component that has been ordered from least to highest\n",
    "    patch_data = A.data[A.indptr[i]:A.indptr[i + 1]]\n",
    "    indx = np.argsort(patch_data)[::-1]\n",
    "\n",
    "    if thr_method == 'nrg':\n",
    "        cumEn = np.cumsum(patch_data[indx]**2)\n",
    "        if len(cumEn) == 0:\n",
    "            pars = dict(\n",
    "                coordinates=np.array([]),\n",
    "                CoM=np.array([np.NaN, np.NaN]),\n",
    "                neuron_id=i + 1,\n",
    "            )\n",
    "            coordinates.append(pars)\n",
    "            continue\n",
    "        else:\n",
    "            # we work with normalized values\n",
    "            cumEn /= cumEn[-1]\n",
    "            Bvec = np.ones(d)\n",
    "            # we put it in a similar matrix\n",
    "            Bvec[A.indices[A.indptr[i]:A.indptr[i + 1]][indx]] = cumEn\n",
    "    else:\n",
    "        Bvec = np.zeros(d)\n",
    "        Bvec[A.indices[A.indptr[i]:A.indptr[i + 1]]] = patch_data / patch_data.max()\n",
    "\n",
    "    if swap_dim:\n",
    "        Bmat = np.reshape(Bvec, dims, order='C')\n",
    "    else:\n",
    "        Bmat = np.reshape(Bvec, dims, order='F')\n",
    "\n",
    "    r_mask = np.zeros_like(Bmat, dtype='bool')\n",
    "    contour = find_contours(Bmat, thr)\n",
    "    for c in contour:\n",
    "        r_mask[np.round(c[:, 0]).astype('int'), np.round(c[:, 1]).astype('int')] = 1\n",
    "    \n",
    "    # Fill in the hole created by the contour boundary\n",
    "    r_mask = binary_fill_holes(r_mask)\n",
    "    ims.append(r_mask + (i * r_mask))\n",
    "#     ims.append(r_mask)\n",
    "ims = np.stack(ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35cf054",
   "metadata": {},
   "outputs": [],
   "source": [
    "ims = ims.astype(np.float32)\n",
    "ims[ims == 0] = np.nan\n",
    "for c in sparse_rois:\n",
    "    plt.plot(*c)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.imshow(np.nanmax(ims, axis=0), cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24d8432",
   "metadata": {},
   "outputs": [],
   "source": [
    "ims = ims.astype(np.float32)\n",
    "ims[ims == 0] = np.nan\n",
    "plt.imshow(np.nanmax(ims, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9802d8d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
